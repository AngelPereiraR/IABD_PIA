{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI96yr6gYJNr",
        "outputId": "889306ad-2f07-4c0b-ed20-462ff383e202"
      },
      "outputs": [],
      "source": [
        "# Importar las bibliotecas\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from openai import OpenAI\n",
        "import faiss\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKxXObJJgIws"
      },
      "source": [
        "Mejor tener el modelo en embedings descagado de HugginFaces que tarda mucho en cargar (lede salesforce son 15 gigas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# Cargar el tokenizer y el modelo\n",
        "model_name = \"BAAI/llm-embedder\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY5He1X0cOqL"
      },
      "outputs": [],
      "source": [
        "# Cargar y dividir el documento\n",
        "def load_and_split_document(file_path):\n",
        "    loader = TextLoader(file_path)\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    return texts\n",
        "\n",
        "# Generar embeddings\n",
        "def generate_embeddings(texts):\n",
        "    embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n",
        "\n",
        "    #embed_model = HuggingFaceEmbeddings(model_name=\"Salesforce/SFR-Embedding-2_R\")\n",
        "    #embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v2\")\n",
        "    #embed_model = HuggingFaceEmbeddings(model_name=\"intfloat/e5-large-v2\")\n",
        "    embeddings = embed_model.embed_documents([text.page_content for text in texts])\n",
        "\n",
        "    return embeddings, embed_model\n",
        "\n",
        "# Crear un índice FAISS\n",
        "def create_faiss_index(embeddings):\n",
        "    embeddings_array = np.array(embeddings)\n",
        "    dimension = embeddings_array.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings_array)\n",
        "    return index\n",
        "\n",
        "# Recuperar el contexto relevante\n",
        "def retrieve_context(query, index, texts, embed_model, top_k=4):\n",
        "    query_embedding = embed_model.embed_query(query)\n",
        "    query_embedding = np.array(query_embedding).reshape(1, -1)\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    relevant_chunks = [texts[i].page_content for i in indices[0]]\n",
        "    return relevant_chunks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4K2t7MoearO"
      },
      "source": [
        "embed_model = HuggingFaceEmbeddings(model_name=\"intfloat/e5-large-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "r83YdiTGzxZi",
        "outputId": "c18ad54e-715f-4669-ee31-5a40886da58e"
      },
      "outputs": [],
      "source": [
        "# Preguntar a DeepSeek\n",
        "def ask_deepseek(query, index, texts, embed_model):\n",
        "    client = OpenAI(api_key=\"\", base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "    # Recuperar el contexto relevante\n",
        "    context = retrieve_context(query, index, texts, embed_model)\n",
        "    context_str = \"\\n\".join(context)\n",
        "\n",
        "    # Crear el mensaje para DeepSeek\n",
        "    messages = [\n",
        "       # {\"role\": \"system\", \"content\": \"Eres atención a cliente de un colegio da respuestas escuetas y concisas basadas en la información del docuemnto adjunto responde en el mismo idioma que te pregunten\"},\n",
        "        {\"role\": \"system\", \"content\": \"Eres un inspector de educación responde docuemnto adjunto responde en el mismo idioma que te pregunten y opina sobre la cuestión como inspector\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Context:\\n{context_str}\\n\\nQuestion: {query}\"},\n",
        "    ]\n",
        "\n",
        "    # Enviar la solicitud a DeepSeek\n",
        "    response = client.chat.completions.create(\n",
        "      #  model=\"deepseek-chat\",\n",
        "      model=\"deepseek-chat\",\n",
        "        messages=messages,\n",
        "        stream=False\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Cargar el documento y dividirlo en chunks\n",
        "file_path = \"/content/documento.txt\"  # Cambia la ruta a tu archivo\n",
        "texts = load_and_split_document(file_path)\n",
        "\n",
        "# Generar embeddings\n",
        "embeddings, embed_model = generate_embeddings(texts)\n",
        "\n",
        "# Crear el índice FAISS\n",
        "index = create_faiss_index(embeddings)\n",
        "\n",
        "# Ejemplo de uso\n",
        "query = \"promoción de primero a segundo\"\n",
        "response = ask_deepseek(query, index, texts, embed_model)\n",
        "print(\"Respuesta de DeepSeek:\\n\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imkN_aTAaDAB",
        "outputId": "d86d5481-e499-409e-ec8a-4cf486ab2de7"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de uso\n",
        "query = \"estudia y da tu opinion sobre principios y valores \"\n",
        "response = ask_deepseek(query, index, texts, embed_model)\n",
        "print(\"Respuesta de DeepSeek:\\n\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UtC1g8WknP1",
        "outputId": "9cd6c695-84fc-485d-e641-5ae1ce7a9567"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de uso\n",
        "query = \"analysiert und gibt eine Stellungnahme zum KOEXISTENZBEREICH ab\"\n",
        "response = ask_deepseek(query, index, texts, embed_model)\n",
        "print(\"Respuesta de DeepSeek:\\n\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRIatI7H2Fll"
      },
      "source": [
        "Ámbito de Convivencia (Koexistenzbereich) se refiere al clima social, la gestión de conflictos y la promoción de una convivencia respetuosa en la comunidad escolar. Del contexto de la Metodología 8.1.4. del Plan de Acción Anual de los Tutores se desprenden los siguientes aspectos clave:\n",
        "\n",
        "Integración en la autoevaluación y mejora:\n",
        "El plan enfatiza que el diagnóstico debe abarcar todas las áreas de la escuela, incluyendo los seis factores clave (presumiblemente también el ámbito de convivencia). Esto es positivo, ya que una convivencia armoniosa es un requisito para un aprendizaje efectivo. Sin embargo, faltan herramientas o indicadores concretos para identificar conflictos, acoso escolar o la efectividad de las medidas preventivas.\n",
        "\n",
        "Rol de las TIC para fomentar la diversidad:\n",
        "El énfasis en las TIC como herramienta para garantizar la diversidad es relevante, por ejemplo, mediante plataformas digitales para la comunicación inclusiva o formación en ética digital. El ámbito de convivencia podría beneficiarse más si se utilizaran las TIC de manera específica para fomentar la empatía (por ejemplo, proyectos de intercambio virtual) o para la denuncia anónima de conflictos.\n",
        "\n",
        "Evaluación y mejora continua:\n",
        "El plan establece que las necesidades de desarrollo se derivan de la autoevaluación anual. Para el ámbito de convivencia, esto implica que deberían realizarse encuestas regulares entre estudiantes, profesores y padres para identificar fortalezas y debilidades. No obstante, no queda claro cómo se traducen estos datos en acciones concretas (por ejemplo, programas de mediación, talleres de inteligencia emocional).\n",
        "\n",
        "Evaluación crítica como inspector escolar:\n",
        "\n",
        "Fortalezas: La integración del ámbito de convivencia en el ciclo de mejora escolar está bien planteada en términos generales. El énfasis en las TIC como elemento de apoyo muestra modernidad.\n",
        "\n",
        "Debilidades: Faltan estrategias específicas para la prevención e intervención en conflictos. El diagnóstico es demasiado general, sin criterios claros o indicadores cuantitativos/cualitativos para el ámbito de convivencia.\n",
        "\n",
        "Recomendaciones:\n",
        "\n",
        "Desarrollo de un catálogo de medidas concretas para el ámbito de convivencia (por ejemplo, mediación entre iguales, gestión digital de quejas).\n",
        "\n",
        "Involucrar a expertos externos (por ejemplo, psicólogos escolares) en la autoevaluación.\n",
        "\n",
        "Utilizar herramientas TIC para la recopilación anónima de conflictos y fomentar la participación (por ejemplo, aplicaciones de feedback digital).\n",
        "\n",
        "Formación regular para el profesorado en \"Aprendizaje Social y Ciudadanía Digital\".\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
